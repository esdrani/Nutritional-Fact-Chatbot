{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\libra\\anaconda3\\envs\\chatbot-env-py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset\\FOOD-DATA-GROUP1.csv successfully.\n",
      "Loaded Dataset\\FOOD-DATA-GROUP2.csv successfully.\n",
      "Loaded Dataset\\FOOD-DATA-GROUP3.csv successfully.\n",
      "Loaded Dataset\\FOOD-DATA-GROUP4.csv successfully.\n",
      "Loaded Dataset\\FOOD-DATA-GROUP5.csv successfully.\n",
      "Merged dataset shape before cleaning: (2395, 37)\n",
      "Dataset shape after removing extra columns: (2395, 35)\n",
      "Dataset shape after removing duplicates: (2395, 35)\n",
      "Missing values per column:\n",
      "food                    0\n",
      "Caloric Value           0\n",
      "Fat                     0\n",
      "Saturated Fats          0\n",
      "Monounsaturated Fats    0\n",
      "Polyunsaturated Fats    0\n",
      "Carbohydrates           0\n",
      "Sugars                  0\n",
      "Protein                 0\n",
      "Dietary Fiber           0\n",
      "Cholesterol             0\n",
      "Sodium                  0\n",
      "Water                   0\n",
      "Vitamin A               0\n",
      "Vitamin B1              0\n",
      "Vitamin B11             0\n",
      "Vitamin B12             0\n",
      "Vitamin B2              0\n",
      "Vitamin B3              0\n",
      "Vitamin B5              0\n",
      "Vitamin B6              0\n",
      "Vitamin C               0\n",
      "Vitamin D               0\n",
      "Vitamin E               0\n",
      "Vitamin K               0\n",
      "Calcium                 0\n",
      "Copper                  0\n",
      "Iron                    0\n",
      "Magnesium               0\n",
      "Manganese               0\n",
      "Phosphorus              0\n",
      "Potassium               0\n",
      "Selenium                0\n",
      "Zinc                    0\n",
      "Nutrition Density       0\n",
      "dtype: int64\n",
      "Descriptive statistics for numeric columns:\n",
      "       Caloric Value          Fat  Saturated Fats  Monounsaturated Fats  \\\n",
      "count    2395.000000  2395.000000     2395.000000           2395.000000   \n",
      "mean      223.769520    10.176276        3.924917              4.133622   \n",
      "std       384.728244    29.008915       19.502262             12.939587   \n",
      "min         0.000000     0.000000        0.000000              0.000000   \n",
      "25%        44.500000     0.300000        0.064000              0.058000   \n",
      "50%       117.000000     2.100000        0.500000              0.500000   \n",
      "75%       258.000000     9.400000        2.700000              3.400000   \n",
      "max      6077.000000   550.700000      672.000000            291.100000   \n",
      "\n",
      "       Polyunsaturated Fats  Carbohydrates       Sugars      Protein  \\\n",
      "count           2395.000000    2395.000000  2395.000000  2395.000000   \n",
      "mean               2.152844      18.589021     4.457459    13.400777   \n",
      "std                7.145738      29.406134    13.339929    32.294246   \n",
      "min                0.000000       0.000000     0.000000     0.000000   \n",
      "25%                0.071000       0.500000     0.000000     0.800000   \n",
      "50%                0.400000       6.800000     0.086000     3.500000   \n",
      "75%                1.700000      25.050000     3.200000    13.300000   \n",
      "max              188.000000     390.200000   291.500000   560.300000   \n",
      "\n",
      "       Dietary Fiber   Cholesterol  ...      Calcium       Copper  \\\n",
      "count    2395.000000   2395.000000  ...  2395.000000  2395.000000   \n",
      "mean        2.235790     62.171937  ...    52.047728     9.581689   \n",
      "std         5.404483    385.352876  ...   115.933379    69.912400   \n",
      "min         0.000000      0.000000  ...     0.000000     0.000000   \n",
      "25%         0.000000      0.000000  ...     0.600000     0.040000   \n",
      "50%         0.200000      0.000000  ...    13.900000     0.100000   \n",
      "75%         2.200000     26.450000  ...    48.250000     0.400000   \n",
      "max        76.500000  10509.000000  ...  1283.500000  1890.000000   \n",
      "\n",
      "              Iron    Magnesium    Manganese   Phosphorus     Potassium  \\\n",
      "count  2395.000000  2395.000000  2395.000000  2395.000000   2395.000000   \n",
      "mean      1.853271    34.429792     5.349964   156.236052    303.833939   \n",
      "std       5.155650    71.927990    21.005332   333.257099    589.507589   \n",
      "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
      "25%       0.100000     1.500000     0.037000     0.800000     27.750000   \n",
      "50%       0.600000    10.400000     0.200000    42.300000    112.300000   \n",
      "75%       1.800000    36.950000     0.700000   171.350000    340.500000   \n",
      "max     121.200000   921.600000   451.000000  5490.000000  11336.900000   \n",
      "\n",
      "          Selenium         Zinc  Nutrition Density  \n",
      "count  2395.000000  2395.000000        2395.000000  \n",
      "mean     52.258006     1.579192         106.929006  \n",
      "std     199.257203     4.937509         173.023891  \n",
      "min       0.000000     0.000000           0.000000  \n",
      "25%       0.016000     0.055000          16.876500  \n",
      "50%       0.053000     0.300000          53.840000  \n",
      "75%       0.090000     1.200000         135.074500  \n",
      "max    3308.000000   147.300000        3911.400000  \n",
      "\n",
      "[8 rows x 34 columns]\n",
      "Example food entry for 'cream cheese':\n",
      "{'Caloric Value': 51, 'Fat': 5.0, 'Saturated Fats': 2.9, 'Monounsaturated Fats': 1.3, 'Polyunsaturated Fats': 0.2, 'Carbohydrates': 0.8, 'Sugars': 0.5, 'Protein': 0.9, 'Dietary Fiber': 0.0, 'Cholesterol': 14.6, 'Sodium': 0.016, 'Water': 7.6, 'Vitamin A': 0.2, 'Vitamin B1': 0.033, 'Vitamin B11': 0.064, 'Vitamin B12': 0.092, 'Vitamin B2': 0.097, 'Vitamin B3': 0.084, 'Vitamin B5': 0.052, 'Vitamin B6': 0.096, 'Vitamin C': 0.004, 'Vitamin D': 0.0, 'Vitamin E': 0.0, 'Vitamin K': 0.1, 'Calcium': 0.008, 'Copper': 14.1, 'Iron': 0.082, 'Magnesium': 0.027, 'Manganese': 1.3, 'Phosphorus': 0.091, 'Potassium': 15.5, 'Selenium': 19.1, 'Zinc': 0.039, 'Nutrition Density': 7.07}\n",
      "Cleaned dataset saved as 'Dataset\\FOOD-DATA-MERGED_CLEANED.csv'.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://0194756c91d87025ed.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0194756c91d87025ed.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################\n",
    "# Complete End-to-End Nutrition Chatbot\n",
    "###########################################\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Import Modules\n",
    "# -------------------------------\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import threading\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Set Up OpenAI API Key Securely\n",
    "# -------------------------------\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Remove or comment out the line setting the key directly\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Data Preprocessing (Segment 1)\n",
    "# -------------------------------\n",
    "# Define your dataset folder (use the absolute path)\n",
    "dataset_folder = \"Dataset\"\n",
    "\n",
    "# List of your five CSV files\n",
    "csv_files = [\n",
    "    os.path.join(dataset_folder, \"FOOD-DATA-GROUP1.csv\"),\n",
    "    os.path.join(dataset_folder, \"FOOD-DATA-GROUP2.csv\"),\n",
    "    os.path.join(dataset_folder, \"FOOD-DATA-GROUP3.csv\"),\n",
    "    os.path.join(dataset_folder, \"FOOD-DATA-GROUP4.csv\"),\n",
    "    os.path.join(dataset_folder, \"FOOD-DATA-GROUP5.csv\")\n",
    "]\n",
    "\n",
    "# Load and merge the CSV files\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"Loaded {file} successfully.\")\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "        \n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Merged dataset shape before cleaning:\", data.shape)\n",
    "\n",
    "# Remove extra columns (headers starting with 'Unnamed')\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "print(\"Dataset shape after removing extra columns:\", data.shape)\n",
    "\n",
    "# Standardize the 'food' column (make lowercase and trim spaces)\n",
    "if 'food' in data.columns:\n",
    "    data['food'] = data['food'].str.lower().str.strip()\n",
    "else:\n",
    "    print(\"Warning: 'food' column not found in dataset!\")\n",
    "\n",
    "# Remove duplicate food entries\n",
    "data = data.drop_duplicates(subset=['food'])\n",
    "print(\"Dataset shape after removing duplicates:\", data.shape)\n",
    "\n",
    "# Convert all columns (except 'food') to numeric and fill missing values with 0\n",
    "numeric_cols = data.columns.drop('food')\n",
    "for col in numeric_cols:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "data[numeric_cols] = data[numeric_cols].fillna(0)\n",
    "\n",
    "# (Optional) Print missing values and descriptive statistics for verification\n",
    "print(\"Missing values per column:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"Descriptive statistics for numeric columns:\")\n",
    "print(data[numeric_cols].describe())\n",
    "\n",
    "# Build a lookup dictionary: key = food name, value = nutritional info (as a dictionary)\n",
    "food_dict = {row['food']: row.drop('food').to_dict() for _, row in data.iterrows()}\n",
    "example_food = list(food_dict.keys())[0]\n",
    "print(f\"Example food entry for '{example_food}':\")\n",
    "print(food_dict[example_food])\n",
    "\n",
    "# Save the cleaned dataset for future use\n",
    "output_path = os.path.join(dataset_folder, \"FOOD-DATA-MERGED_CLEANED.csv\")\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned dataset saved as '{output_path}'.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Chatbot Query Processing & IR-based Retrieval (Segment 2)\n",
    "# -------------------------------\n",
    "def retrieve_results(query, top_n=3):\n",
    "    \"\"\"\n",
    "    Builds a mini-corpus (food name plus nutritional info) and uses TF-IDF with cosine similarity\n",
    "    to retrieve the top matching food entries.\n",
    "    \"\"\"\n",
    "    keys = list(food_dict.keys())\n",
    "    documents = []\n",
    "    for f in keys:\n",
    "        info_str = \", \".join([f\"{k}: {v}\" for k, v in food_dict[f].items()])\n",
    "        documents.append(f\"{f}. {info_str}\")\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    top_indices = sims.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"FoodName\": keys[idx],\n",
    "            \"Nutrition\": food_dict[keys[idx]],\n",
    "            \"similarity\": float(sims[idx])\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Retrieval-Augmented Generation (RAG) with OpenAI (Segment 3)\n",
    "# -------------------------------\n",
    "def generate_conversational_answer(query, context):\n",
    "    \"\"\"\n",
    "    Uses OpenAI's GPT-4-0314 to generate a polite, detailed answer based on the query and provided nutritional context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = (\n",
    "            f\"Here is the nutritional data:\\n{context}\\n\"\n",
    "            f\"Please provide a detailed, polite answer to the following question:\\n{query}\"\n",
    "        )\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-0314\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response.choices[0].message['content']\n",
    "    except Exception as e:\n",
    "        print(\"OpenAI API error:\", e)\n",
    "        return None\n",
    "\n",
    "def generate_answer(query):\n",
    "    \"\"\"\n",
    "    Processes the user's query to identify the nutrient keyword, \n",
    "    attempts substring-based partial matches for the food name, \n",
    "    and if that fails, uses TF-IDF-based retrieval.\n",
    "    Then returns a final GPT-4-0314 augmented answer.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # 1. Identify nutrient keyword (if any)\n",
    "    nutrient_found = None\n",
    "    nutrient_keywords = [\n",
    "        \"calories\", \"fat\", \"protein\", \"carbohydrates\", \"sugars\",\n",
    "        \"fiber\", \"cholesterol\", \"sodium\", \"vitamin\", \"mineral\"\n",
    "    ]\n",
    "    for kw in nutrient_keywords:\n",
    "        if kw in query_lower:\n",
    "            nutrient_found = kw\n",
    "            break\n",
    "\n",
    "    # 2. Attempt partial substring matches for the food name\n",
    "    partial_matches = []\n",
    "    for food_name in food_dict.keys():\n",
    "        if food_name in query_lower or query_lower in food_name:\n",
    "            partial_matches.append(food_name)\n",
    "\n",
    "    if len(partial_matches) == 1:\n",
    "        # Exactly one partial match -> pick it\n",
    "        chosen_food = partial_matches[0]\n",
    "        print(f\"[DEBUG] Substring-based match found: {chosen_food}\")\n",
    "        food_item = chosen_food\n",
    "    elif len(partial_matches) > 1:\n",
    "        # Multiple partial matches -> ask user to specify\n",
    "        matches_str = \", \".join(partial_matches[:10])  # show up to 10 matches\n",
    "        return (None, f\"I found multiple foods containing that name: {matches_str}. Please specify which one you mean.\")\n",
    "    else:\n",
    "        # 3. No partial substring match found -> fallback to TF-IDF retrieval\n",
    "        retrieved = retrieve_results(query, top_n=3)\n",
    "        if not retrieved:\n",
    "            return (None, \"I couldn't find any matching foods. Please try a different query.\")\n",
    "\n",
    "        # Sort by similarity\n",
    "        retrieved = sorted(retrieved, key=lambda x: x[\"similarity\"], reverse=True)\n",
    "        top1 = retrieved[0]\n",
    "        sim1 = top1[\"similarity\"]\n",
    "        sim2 = retrieved[1][\"similarity\"] if len(retrieved) > 1 else 0.0\n",
    "\n",
    "        # Confidence thresholds\n",
    "        confidence_threshold = 0.2\n",
    "        separation_threshold = 0.05\n",
    "\n",
    "        # If the top match is below confidence_threshold, indicate uncertainty\n",
    "        if sim1 < confidence_threshold:\n",
    "            return (None, \"I'm not sure which food you mean. Could you be more specific?\")\n",
    "\n",
    "        # If the top two matches are too close, ask the user to clarify\n",
    "        if (sim1 - sim2) < separation_threshold and len(retrieved) > 1:\n",
    "            candidates = [item[\"FoodName\"] for item in retrieved]\n",
    "            return (None, f\"I found multiple possible matches: {', '.join(candidates)}. Please specify which one you meant.\")\n",
    "\n",
    "        # Use the best match\n",
    "        food_item = top1[\"FoodName\"]\n",
    "\n",
    "    # 4. Retrieve the food info from the dictionary\n",
    "    info = food_dict.get(food_item)\n",
    "    if not info:\n",
    "        return (None, f\"Found '{food_item}' but no nutritional info is available, sorry.\")\n",
    "\n",
    "    # 5. Build a basic answer (direct nutrient lookup or summary)\n",
    "    if nutrient_found:\n",
    "        nutrient_value = None\n",
    "        for k in info.keys():\n",
    "            if nutrient_found in k.lower():\n",
    "                nutrient_value = info[k]\n",
    "                break\n",
    "        if nutrient_value is not None:\n",
    "            basic_answer = f\"The {nutrient_found} content of {food_item} is {nutrient_value} per serving.\"\n",
    "        else:\n",
    "            basic_answer = f\"Sorry, I could not find information on {nutrient_found} for {food_item}.\"\n",
    "    else:\n",
    "        summary_keys = [\"calories\", \"fat\", \"protein\", \"carbohydrates\"]\n",
    "        details = []\n",
    "        for s in summary_keys:\n",
    "            for k in info.keys():\n",
    "                if s in k.lower():\n",
    "                    details.append(f\"{s}: {info[k]}\")\n",
    "                    break\n",
    "        basic_answer = f\"Here is the nutritional info for {food_item}: {', '.join(details)}.\"\n",
    "\n",
    "    # 6. Use RAG approach with GPT for a detailed answer\n",
    "    retrieved_context = retrieve_results(food_item, top_n=3)\n",
    "    context_str = \"\\n\".join([\n",
    "        f\"{item['FoodName']}: \" + \", \".join([f\"{k}: {v}\" for k, v in item['Nutrition'].items()]) +\n",
    "        f\" (similarity: {item['similarity']:.2f})\"\n",
    "        for item in retrieved_context\n",
    "    ])\n",
    "\n",
    "    final_answer = generate_conversational_answer(query, context_str)\n",
    "    if not final_answer or \"error\" in final_answer.lower():\n",
    "        final_answer = basic_answer\n",
    "\n",
    "    return (food_item, final_answer)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Image Classification Placeholder (Segment 4)\n",
    "# -------------------------------\n",
    "def classify_image(image):\n",
    "    \"\"\"\n",
    "    A placeholder function for image classification.\n",
    "    Currently, it simply prints the image size.\n",
    "    Future integration can involve models (e.g., Hugging Face's ViT) to classify food.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from transformers import AutoProcessor, AutoModelForImageClassification\n",
    "        from PIL import Image\n",
    "        # Process the image using a pre-trained model\n",
    "        processor = AutoProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        predicted_class = outputs.logits.argmax(-1).item()\n",
    "        return predicted_class\n",
    "    except Exception as e:\n",
    "        print(\"Error in image classification:\", e)\n",
    "        return None\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Gradio Chatbot Interface (Segment 5)\n",
    "# -------------------------------\n",
    "def chatbot_interface(user_input, user_image):\n",
    "    \"\"\"\n",
    "    Gradio interface for the chatbot.\n",
    "    If an image is uploaded, it prints the image size (placeholder for future integration).\n",
    "    Then it processes the text query and returns the answer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process image if provided (currently, only prints its size)\n",
    "        if user_image is not None:\n",
    "            print(\"User uploaded an image of size:\", user_image.size)\n",
    "            # Uncomment below to integrate image classification:\n",
    "            # recognized_class = classify_image(user_image)\n",
    "            # user_input += f\" recognized as: {recognized_class}\"\n",
    "        \n",
    "        # Process the text query and generate an answer\n",
    "        _, answer = generate_answer(user_input)\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Build and Launch the Gradio Interface\n",
    "# -------------------------------\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot_interface,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Your Question\"),\n",
    "        gr.Image(label=\"Upload an image (optional)\", type=\"pil\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    "    title=\"Enhanced Food Nutrition Chatbot\",\n",
    "    description=\"Ask nutrition questions about food, or upload an image placeholder!\"\n",
    ")\n",
    "\n",
    "# Launch the interface. The Gradio app will display a local URL and generate a public share link.\n",
    "iface.launch(debug=True, share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
